{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOggZILUOnnvE0wbDg5cKrH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8GEsozrxSgg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import gc\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GLU(nn.Module):\n",
        "    \"\"\"\n",
        "      The Gated Linear Unit GLU(a,b) = mult(a,sigmoid(b)) is common in NLP\n",
        "      architectures like the Gated CNN. Here sigmoid(b) corresponds to a gate\n",
        "      that controls what information from a is passed to the following layer.\n",
        "\n",
        "      Args:\n",
        "          input_size (int): number defining input and output size of the gate\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input\n",
        "        self.a = nn.Linear(input_size, input_size)\n",
        "\n",
        "        # Gate\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.b = nn.Linear(input_size, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.tensor): tensor passing through the gate\n",
        "        \"\"\"\n",
        "        gate = self.sigmoid(self.b(x))\n",
        "        x = self.a(x)\n",
        "\n",
        "        return torch.mul(gate, x)"
      ],
      "metadata": {
        "id": "F2R9gHtKxTn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalLayer(nn.Module):\n",
        "    def __init__(self, module):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Collapses input of dim T*N*H to (T*N)*H, and applies to a module.\n",
        "        Allows handling of variable sequence lengths and minibatch sizes.\n",
        "\n",
        "        Similar to TimeDistributed in Keras, it is a wrapper that makes it possible\n",
        "        to apply a layer to every temporal slice of an input.\n",
        "        \"\"\"\n",
        "        self.module = module\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.tensor): tensor with time steps to pass through the same layer.\n",
        "        \"\"\"\n",
        "        t, n = x.size(0), x.size(1)\n",
        "        x = x.reshape(t * n, -1)\n",
        "        x = self.module(x)\n",
        "        x = x.reshape(t, n, x.size(-1))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "WVkVEjWgxWjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GatedResidualNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "      The Gated Residual Network gives the model flexibility to apply non-linear\n",
        "      processing only when needed. It is difficult to know beforehand which\n",
        "      variables are relevant and in some cases simpler models can be beneficial.\n",
        "\n",
        "      GRN(a, c) = LayerNorm(a + GLU(eta_1)) # Dropout is applied to eta_1\n",
        "        eta_1 = W_1*eta_2 + b_1\n",
        "        eta_2 = ELU(W_2*a + W_3*c + b_2)\n",
        "\n",
        "      Args:\n",
        "          input_size (int): Size of the input\n",
        "          hidden_size (int): Size of the hidden layer\n",
        "          output_size (int): Size of the output layer\n",
        "          dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
        "          context_size (int): Size of the static context vector\n",
        "          is_temporal (bool): Flag to decide if TemporalLayer has to be used or not\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, dropout, context_size=None, is_temporal=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.context_size = context_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = dropout\n",
        "        self.is_temporal = is_temporal\n",
        "\n",
        "        if self.is_temporal:\n",
        "            if self.input_size != self.output_size:\n",
        "                self.skip_layer = TemporalLayer(nn.Linear(self.input_size, self.output_size))\n",
        "\n",
        "            # Context vector c\n",
        "            if self.context_size != None:\n",
        "                self.c = TemporalLayer(nn.Linear(self.context_size, self.hidden_size, bias=False))\n",
        "\n",
        "            # Dense & ELU\n",
        "            self.dense1 = TemporalLayer(nn.Linear(self.input_size, self.hidden_size))\n",
        "            self.elu = nn.ELU()\n",
        "\n",
        "            # Dense & Dropout\n",
        "            self.dense2 = TemporalLayer(nn.Linear(self.hidden_size,  self.output_size))\n",
        "            self.dropout = nn.Dropout(self.dropout)\n",
        "\n",
        "            # Gate, Add & Norm\n",
        "            self.gate = TemporalLayer(GLU(self.output_size))\n",
        "            self.layer_norm = TemporalLayer(nn.LayerNorm(self.output_size))\n",
        "\n",
        "        else:\n",
        "            if self.input_size != self.output_size:\n",
        "                self.skip_layer = nn.Linear(self.input_size, self.output_size)\n",
        "\n",
        "            # Context vector c\n",
        "            if self.context_size != None:\n",
        "                self.c = nn.Linear(self.context_size, self.hidden_size, bias=False)\n",
        "\n",
        "            # Dense & ELU\n",
        "            self.dense1 = nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.elu = nn.ELU()\n",
        "\n",
        "            # Dense & Dropout\n",
        "            self.dense2 = nn.Linear(self.hidden_size,  self.output_size)\n",
        "            self.dropout = nn.Dropout(self.dropout)\n",
        "\n",
        "            # Gate, Add & Norm\n",
        "            self.gate = GLU(self.output_size)\n",
        "            self.layer_norm = nn.LayerNorm(self.output_size)\n",
        "\n",
        "\n",
        "    def forward(self, x, c=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.tensor): tensor thas passes through the GRN\n",
        "            c (torch.tensor): Optional static context vector\n",
        "        \"\"\"\n",
        "\n",
        "        if self.input_size!=self.output_size:\n",
        "            a = self.skip_layer(x)\n",
        "        else:\n",
        "            a = x\n",
        "\n",
        "        x = self.dense1(x)\n",
        "\n",
        "        if c != None:\n",
        "            c = self.c(c.unsqueeze(1))\n",
        "            x += c\n",
        "\n",
        "        eta_2 = self.elu(x)\n",
        "\n",
        "        eta_1 = self.dense2(eta_2)\n",
        "        eta_1 = self.dropout(eta_1)\n",
        "\n",
        "        gate = self.gate(eta_1)\n",
        "        gate += a\n",
        "        x = self.layer_norm(gate)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "SxtxTSStxZUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableSelectionNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "      The Variable Selection Network gives the model the ability to remove\n",
        "      unnecessary noisy inputs that could have a negative impact on performance.\n",
        "      It also allows us to better understand which variables are most important\n",
        "      for the prediction task.\n",
        "\n",
        "      The variable selection weights are created by feeding both the flattened\n",
        "      vector of all past inputs at time t (E_t) and an optional context vector\n",
        "      through a GRN, followed by a Softmax layer.\n",
        "\n",
        "      V_xt = Softmax(GRN_v(E_t, c_s))\n",
        "\n",
        "      Also, the feature vector for each variable is fed through its\n",
        "      own GRN to create an additional layer of non-linear processing.\n",
        "\n",
        "      Processed features are then weighted by the variable selection weights\n",
        "      and combined.\n",
        "\n",
        "      Args:\n",
        "          input_size (int): Size of the input\n",
        "          output_size (int): Size of the output layer\n",
        "          hidden_size (int): Size of the hidden layer\n",
        "          dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
        "          context_size (int): Size of the static context vector\n",
        "          is_temporal (bool): Flag to decide if TemporalLayer has to be used or not\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, hidden_size, dropout, context_size=None, is_temporal=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout = dropout\n",
        "        self.context_size = context_size\n",
        "        self.is_temporal = is_temporal\n",
        "\n",
        "        self.flattened_inputs = GatedResidualNetwork(self.output_size*self.input_size,\n",
        "                                                     self.hidden_size, self.output_size,\n",
        "                                                     self.dropout, self.context_size,\n",
        "                                                     self.is_temporal)\n",
        "\n",
        "        self.transformed_inputs = nn.ModuleList(\n",
        "            [GatedResidualNetwork(\n",
        "                self.input_size, self.hidden_size, self.hidden_size,\n",
        "                self.dropout, self.context_size, self.is_temporal) for i in range(self.output_size)])\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "\n",
        "    def forward(self, embedding, context=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          embedding (torch.tensor): Entity embeddings for categorical variables and linear\n",
        "                     transformations for continuous variables.\n",
        "          context (torch.tensor): The context is obtained from a static covariate encoder and\n",
        "                   is naturally omitted for static variables as they already\n",
        "                   have access to this\n",
        "        \"\"\"\n",
        "\n",
        "        # Generation of variable selection weights\n",
        "        sparse_weights = self.flattened_inputs(embedding, context)\n",
        "        if self.is_temporal:\n",
        "            sparse_weights = self.softmax(sparse_weights).unsqueeze(2)\n",
        "        else:\n",
        "            sparse_weights = self.softmax(sparse_weights).unsqueeze(1)\n",
        "\n",
        "        # Additional non-linear processing for each feature vector\n",
        "        transformed_embeddings = torch.stack(\n",
        "            [self.transformed_inputs[i](embedding[\n",
        "                Ellipsis, i*self.input_size:(i+1)*self.input_size]) for i in range(self.output_size)], axis=-1)\n",
        "\n",
        "        # Processed features are weighted by their corresponding weights and combined\n",
        "        combined = transformed_embeddings*sparse_weights\n",
        "        combined = combined.sum(axis=-1)\n",
        "\n",
        "        return combined, sparse_weights"
      ],
      "metadata": {
        "id": "JG5xC94nxccR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention mechansims usually scale values based on relationships between\n",
        "    keys and queries.\n",
        "\n",
        "    Attention(Q,K,V) = A(Q,K)*V where A() is a normalization function.\n",
        "\n",
        "    A common choice for the normalization function is scaled dot-product attention:\n",
        "\n",
        "    A(Q,K) = Softmax(Q*K^T / sqrt(d_attention))\n",
        "\n",
        "    Args:\n",
        "          dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          query (torch.tensor):\n",
        "          key (torch.tensor):\n",
        "          value (torch.tensor):\n",
        "          mask (torch.tensor):\n",
        "        \"\"\"\n",
        "\n",
        "        d_k = key.shape[-1]\n",
        "        scaling_factor = torch.sqrt(torch.tensor(d_k).to(torch.float32))\n",
        "\n",
        "        scaled_dot_product = torch.matmul(query, key.permute(0,2,1)) / scaling_factor\n",
        "        if mask != None:\n",
        "            scaled_dot_product = scaled_dot_product.masked_fill(mask == 0, -1e9)\n",
        "        attention = self.softmax(scaled_dot_product)\n",
        "        attention = self.dropout(attention)\n",
        "        output = torch.matmul(attention, value)\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "4_faBkHjxfgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpretableMultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Different attention heads can be used to improve the learning capacity of\n",
        "    the model.\n",
        "\n",
        "    MultiHead(Q,K,V) = [H_1, ..., H_m]*W_H\n",
        "    H_h = Attention(Q*Wh_Q, K*Wh_K, V*Wh_V)\n",
        "\n",
        "    Each head has specific weights for keys, queries and values. W_H linearly\n",
        "    combines the concatenated outputs from all heads.\n",
        "\n",
        "    To increase interpretability, multi-head attention has been modified to share\n",
        "    values in each head.\n",
        "\n",
        "    InterpretableMultiHead(Q,K,V) = H_I*W_H\n",
        "    H_I = 1/H * SUM(Attention(Q*Wh_Q, K*Wh_K, V*W_V)) # Note that W_V does not depend on the head.\n",
        "\n",
        "    Args:\n",
        "          num_heads (int): Number of attention heads\n",
        "          hidden_size (int): Hidden size of the model\n",
        "          dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
        "    \"\"\"\n",
        "    def __init__(self, num_attention_heads, hidden_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.qs = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size, bias=False) for i in range(self.num_attention_heads)])\n",
        "        self.ks = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size, bias=False) for i in range(self.num_attention_heads)])\n",
        "\n",
        "        vs_layer = nn.Linear(self.hidden_size, self.hidden_size, bias=False) # Value is shared for improved interpretability\n",
        "        self.vs = nn.ModuleList([vs_layer for i in range(self.num_attention_heads)])\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "        self.linear = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "\n",
        "        batch_size, tgt_len, embed_dim = query.shape\n",
        "        head_dim = embed_dim // self.num_attention_heads\n",
        "\n",
        "        # Now we iterate over each head to calculate outputs and attention\n",
        "        heads = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(self.num_attention_heads):\n",
        "            q_i = self.qs[i](query)\n",
        "            k_i = self.ks[i](key)\n",
        "            v_i = self.vs[i](value)\n",
        "\n",
        "            # Reshape q, k, v for multihead attention\n",
        "            q_i = query.reshape(batch_size, tgt_len, self.num_attention_heads, head_dim).transpose(1,2).reshape(batch_size*self.num_attention_heads, tgt_len, head_dim)\n",
        "            k_i = key.reshape(batch_size, tgt_len, self.num_attention_heads, head_dim).transpose(1,2).reshape(batch_size*self.num_attention_heads, tgt_len, head_dim)\n",
        "            v_i = value.reshape(batch_size, tgt_len, self.num_attention_heads, head_dim).transpose(1,2).reshape(batch_size*self.num_attention_heads, tgt_len, head_dim)\n",
        "\n",
        "            head, attention = self.attention(q_i, k_i, v_i, mask)\n",
        "\n",
        "            # Revert to original target shape\n",
        "            head = head.reshape(batch_size, self.num_attention_heads, tgt_len, head_dim).transpose(1,2).reshape(-1, tgt_len, self.num_attention_heads*head_dim)\n",
        "            head_dropout = self.dropout(head)\n",
        "            heads.append(head_dropout)\n",
        "            attentions.append(attention)\n",
        "\n",
        "        # Output the results\n",
        "        if self.num_attention_heads > 1:\n",
        "            heads = torch.stack(heads, dim=2) #.reshape(batch_size, tgt_len, -1, self.hidden_size)\n",
        "            outputs = torch.mean(heads, dim=2)\n",
        "        else:\n",
        "            outputs = head\n",
        "\n",
        "        attentions = torch.stack(attentions, dim=2)\n",
        "        attention = torch.mean(attentions, dim=2)\n",
        "\n",
        "        outputs = self.linear(outputs)\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        return outputs, attention"
      ],
      "metadata": {
        "id": "JO9SoI-ZxhrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantileLoss(nn.Module):\n",
        "    \"\"\"Quantile loss for multiple quantile predictions.\n",
        "\n",
        "    For a given quantile τ, the loss is calculated as:\n",
        "    L = τ * |y - ŷ|     if y > ŷ (underprediction)\n",
        "    L = (1-τ) * |y - ŷ| if y ≤ ŷ (overprediction)\n",
        "\n",
        "    Args:\n",
        "        quantiles (list): List of quantiles to predict (e.g., [0.1, 0.5, 0.9])\n",
        "    \"\"\"\n",
        "    def __init__(self, quantiles):\n",
        "        super().__init__()\n",
        "        self.quantiles = quantiles\n",
        "\n",
        "    def forward(self, preds, target):\n",
        "        \"\"\"Calculate the quantile loss.\n",
        "\n",
        "        Args:\n",
        "            preds (torch.Tensor): Predictions of shape [batch_size, num_quantiles]\n",
        "            target (torch.Tensor): Actual values of shape [batch_size]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Mean quantile loss across all predictions and quantiles\n",
        "        \"\"\"\n",
        "        assert not target.requires_grad\n",
        "        assert preds.size(0) == target.size(0)\n",
        "\n",
        "        losses = []\n",
        "        for i, q in enumerate(self.quantiles):\n",
        "            # Calculate prediction error\n",
        "            errors = target - preds[:, i]\n",
        "\n",
        "            # Calculate quantile loss\n",
        "            # When error >= 0 (underprediction): q * |error|\n",
        "            # When error < 0 (overprediction): (1-q) * |error|\n",
        "            q_loss = torch.max(\n",
        "                (q-1) * errors,  # for positive errors (underprediction)\n",
        "                q  * errors  # for negative errors (overprediction)\n",
        "            ).unsqueeze(1)\n",
        "\n",
        "            losses.append(q_loss)\n",
        "\n",
        "        # Combine losses across all quantiles\n",
        "        loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
        "        return loss"
      ],
      "metadata": {
        "id": "S0BHTrB0xkAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalFusionTransformer(nn.Module):\n",
        "    \"\"\"Creates a Temporal Fusion Transformer model.\n",
        "\n",
        "    For simplicity, arguments are passed within a parameters dictionary\n",
        "\n",
        "    Args:\n",
        "        col_to_idx (dict): Maps column names to their index in input array\n",
        "        static_covariates (list): Names of static covariate variables\n",
        "        time_dependent_categorical (list): Names of time dependent categorical variables\n",
        "        time_dependent_continuous (list): Names of time dependent continuous variables\n",
        "        category_counts (dict): Maps column names to the number of categories of each categorical feature\n",
        "        known_time_dependent (list): Names of known time dependent variables\n",
        "        observed_time_dependent (list): Names of observed time dependent variables\n",
        "        batch_size (int): Batch size\n",
        "        encoder_steps (int): Fixed k time steps to look back for each prediction (also size of LSTM encoder)\n",
        "        hidden_size (int): Internal state size of different layers\n",
        "        num_lstm_layers (int): Number of LSTM layers that should be used\n",
        "        dropout (float): Fraction between 0 and 1 corresponding to the degree of dropout used\n",
        "        embedding_dim (int): Dimensionality of embeddings\n",
        "        num_attention_heads (int): Number of heads for interpretable mulit-head attention\n",
        "        quantiles (list): Quantiles used for prediction. Also defines model output size\n",
        "        device (str): Used to decide between CPU and GPU\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, parameters):\n",
        "        \"\"\"Uses the given parameters to set up the Temporal Fusion Transformer model\n",
        "\n",
        "        Args:\n",
        "          parameters: Dictionary with parameters used to define the model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Inputs\n",
        "        self.col_to_idx = parameters[\"col_to_idx\"]\n",
        "        self.static_covariates = parameters[\"static_covariates\"]\n",
        "        self.time_dependent_categorical = parameters[\"time_dependent_categorical\"]\n",
        "        self.time_dependent_continuous = parameters[\"time_dependent_continuous\"]\n",
        "        self.category_counts = parameters[\"category_counts\"]\n",
        "        self.known_time_dependent = parameters[\"known_time_dependent\"]\n",
        "        self.observed_time_dependent = parameters[\"observed_time_dependent\"]\n",
        "        self.time_dependent = self.known_time_dependent+self.observed_time_dependent\n",
        "\n",
        "        # Architecture\n",
        "        self.batch_size = parameters['batch_size']\n",
        "        self.encoder_steps = parameters['encoder_steps']\n",
        "        self.hidden_size = parameters['hidden_layer_size']\n",
        "        self.num_lstm_layers = parameters['num_lstm_layers']\n",
        "        self.dropout = parameters['dropout']\n",
        "        self.embedding_dim = parameters['embedding_dim']\n",
        "        self.num_attention_heads = parameters['num_attention_heads']\n",
        "\n",
        "        # Outputs\n",
        "        self.quantiles = parameters['quantiles']\n",
        "\n",
        "        # Other\n",
        "        self.device = parameters['device']\n",
        "\n",
        "\n",
        "        # Prepare for input transformation (embeddings for categorical variables and linear transformations for continuous variables)\n",
        "\n",
        "        # Prepare embeddings for the static covariates and static context vectors\n",
        "        self.static_embeddings = nn.ModuleDict({col: nn.Embedding(self.category_counts[col], self.embedding_dim).to(self.device) for col in self.static_covariates})\n",
        "        self.static_variable_selection = VariableSelectionNetwork(self.embedding_dim, len(self.static_covariates), self.hidden_size, self.dropout, is_temporal=False)\n",
        "\n",
        "        self.static_context_variable_selection = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout, is_temporal=False)\n",
        "        self.static_context_enrichment = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout, is_temporal=False)\n",
        "        self.static_context_state_h = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout, is_temporal=False)\n",
        "        self.static_context_state_c = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout, is_temporal=False)\n",
        "\n",
        "        # Prepare embeddings and linear transformations for time dependent variables\n",
        "        self.temporal_cat_embeddings = nn.ModuleDict({col: TemporalLayer(nn.Embedding(self.category_counts[col], self.embedding_dim)).to(self.device) for col in self.time_dependent_categorical})\n",
        "        self.temporal_real_transformations = nn.ModuleDict({col: TemporalLayer(nn.Linear(1, self.embedding_dim)).to(self.device) for col in self.time_dependent_continuous})\n",
        "\n",
        "        # Variable selection and encoder for past inputs\n",
        "        self.past_variable_selection = VariableSelectionNetwork(self.embedding_dim, len(self.time_dependent), self.hidden_size, self.dropout, context_size=self.hidden_size)\n",
        "\n",
        "        # Variable selection and decoder for known future inputs\n",
        "        self.future_variable_selection = VariableSelectionNetwork(self.embedding_dim, len([col for col in self.time_dependent if col not in self.observed_time_dependent]),\n",
        "                                                                  self.hidden_size, self.dropout, context_size=self.hidden_size)\n",
        "\n",
        "        # LSTM encoder and decoder\n",
        "        self.lstm_encoder = nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=self.num_lstm_layers, dropout=self.dropout)\n",
        "        self.lstm_decoder = nn.LSTM(input_size=self.hidden_size, hidden_size=self.hidden_size, num_layers=self.num_lstm_layers, dropout=self.dropout)\n",
        "\n",
        "        # Gated skip connection and normalization\n",
        "        self.gated_skip_connection = TemporalLayer(GLU(self.hidden_size))\n",
        "        self.add_norm = TemporalLayer(nn.BatchNorm1d(self.hidden_size))\n",
        "\n",
        "        # Temporal Fusion Decoder\n",
        "\n",
        "        # Static enrichment layer\n",
        "        self.static_enrichment = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout, self.hidden_size)\n",
        "\n",
        "        # Temporal Self-attention layer\n",
        "        self.multihead_attn = InterpretableMultiHeadAttention(self.num_attention_heads, self.hidden_size)\n",
        "        self.attention_gated_skip_connection = TemporalLayer(GLU(self.hidden_size))\n",
        "        self.attention_add_norm = TemporalLayer(nn.BatchNorm1d(self.hidden_size, self.hidden_size))\n",
        "\n",
        "        # Position-wise feed-forward layer\n",
        "        self.position_wise_feed_forward = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout)\n",
        "\n",
        "        # Output layer\n",
        "        self.output_gated_skip_connection = TemporalLayer(GLU(self.hidden_size))\n",
        "        self.output_add_norm = TemporalLayer(nn.BatchNorm1d(self.hidden_size, self.hidden_size))\n",
        "\n",
        "        self.output = TemporalLayer(nn.Linear(self.hidden_size, len(self.quantiles)))\n",
        "\n",
        "\n",
        "\n",
        "    def define_static_covariate_encoders(self, x):\n",
        "        embedding_vectors = [self.static_embeddings[col](x[:, 0, self.col_to_idx[col]].long().to(self.device)) for col in self.static_covariates]\n",
        "        static_embedding = torch.cat(embedding_vectors, dim=1)\n",
        "        static_encoder, static_weights = self.static_variable_selection(static_embedding)\n",
        "\n",
        "        # Static context vectors\n",
        "        static_context_s = self.static_context_variable_selection(static_encoder) # Context for temporal variable selection\n",
        "        static_context_e = self.static_context_enrichment(static_encoder) # Context for static enrichment layer\n",
        "        static_context_h = self.static_context_state_h(static_encoder) # Context for local processing of temporal features (encoder/decoder)\n",
        "        static_context_c = self.static_context_state_c(static_encoder) # Context for local processing of temporal features (encoder/decoder)\n",
        "\n",
        "        return static_encoder, static_weights, static_context_s, static_context_e, static_context_h, static_context_c\n",
        "\n",
        "\n",
        "    def define_past_inputs_encoder(self, x, context):\n",
        "        for col in self.time_dependent_categorical:\n",
        "          idx = self.col_to_idx[col]\n",
        "          input_indices = x[:, :, idx].long()\n",
        "          if input_indices.max() >= self.category_counts[col]:\n",
        "            raise ValueError(\n",
        "                f\"Category index {input_indices.max()} in column '{col}' \"\n",
        "                f\"exceeds embedding size {self.category_counts[col]}\"\n",
        "             )\n",
        "        embedding_vectors = torch.cat([self.temporal_cat_embeddings[col](x[:, :, self.col_to_idx[col]].long()) for col in self.time_dependent_categorical], dim=2)\n",
        "        transformation_vectors = torch.cat([self.temporal_real_transformations[col](x[:, :, self.col_to_idx[col]]) for col in self.time_dependent_continuous], dim=2)\n",
        "\n",
        "        past_inputs = torch.cat([embedding_vectors, transformation_vectors], dim=2)\n",
        "        past_encoder, past_weights = self.past_variable_selection(past_inputs, context)\n",
        "\n",
        "        return past_encoder.transpose(0, 1), past_weights\n",
        "\n",
        "\n",
        "    def define_known_future_inputs_decoder(self, x, context):\n",
        "        embedding_vectors = torch.cat([self.temporal_cat_embeddings[col](x[:, :, self.col_to_idx[col]].long()) for col in self.time_dependent_categorical if col not in self.observed_time_dependent], dim=2)\n",
        "\n",
        "        transformation_vectors = torch.cat([self.temporal_real_transformations[col](x[:, :, self.col_to_idx[col]]) for col in self.time_dependent_continuous if col not in self.observed_time_dependent], dim=2)\n",
        "\n",
        "        future_inputs = torch.cat([embedding_vectors, transformation_vectors], dim=2)\n",
        "        future_decoder, future_weights = self.future_variable_selection(future_inputs, context)\n",
        "\n",
        "        return future_decoder.transpose(0, 1), future_weights\n",
        "\n",
        "\n",
        "    def define_lstm_encoder(self, x, static_context_h, static_context_c):\n",
        "        output, (state_h, state_c) = self.lstm_encoder(x, (static_context_h.unsqueeze(0).repeat(self.num_lstm_layers,1,1),\n",
        "                                                           static_context_c.unsqueeze(0).repeat(self.num_lstm_layers,1,1)))\n",
        "\n",
        "        return output, state_h, state_c\n",
        "\n",
        "\n",
        "    def define_lstm_decoder(self, x, state_h, state_c):\n",
        "        output, (_, _) = self.lstm_decoder(x, (state_h.unsqueeze(0).repeat(self.num_lstm_layers,1,1),\n",
        "                                               state_c.unsqueeze(0).repeat(self.num_lstm_layers,1,1)))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def get_mask(self, attention_inputs):\n",
        "        #mask = torch.cumsum(torch.eye(attention_inputs.shape[1]*self.num_attention_heads, attention_inputs.shape[0]), dim=1)\n",
        "        mask = torch.cumsum(torch.eye(attention_inputs.shape[0]*self.num_attention_heads, attention_inputs.shape[1]), dim=1)\n",
        "\n",
        "        return mask.unsqueeze(2).to(self.device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Static variable selection and static covariate encoders\n",
        "        static_encoder, static_weights, static_context_s, static_context_e, static_context_h, static_context_c = self.define_static_covariate_encoders(x[\"inputs\"])\n",
        "\n",
        "        # Past input variable selection and LSTM encoder\n",
        "        past_encoder, past_weights = self.define_past_inputs_encoder(x[\"inputs\"][:, :self.encoder_steps, :].float().to(self.device), static_context_s)\n",
        "\n",
        "        # Known future inputs variable selection and LSTM decoder\n",
        "        future_decoder, future_weights = self.define_known_future_inputs_decoder(x[\"inputs\"][:, self.encoder_steps:, :].float().to(self.device), static_context_s)\n",
        "\n",
        "\n",
        "        # Pass output from variable selection through LSTM encoder and decoder\n",
        "        encoder_output, state_h, state_c = self.define_lstm_encoder(past_encoder, static_context_h, static_context_c)\n",
        "        decoder_output = self.define_lstm_decoder(future_decoder, static_context_h, static_context_c)\n",
        "\n",
        "        # Gated skip connection before moving into the Temporal Fusion Decoder\n",
        "        variable_selection_outputs = torch.cat([past_encoder, future_decoder], dim=0)\n",
        "        lstm_outputs = torch.cat([encoder_output, decoder_output], dim=0)\n",
        "        gated_outputs = self.gated_skip_connection(lstm_outputs)\n",
        "        temporal_feature_outputs = self.add_norm(variable_selection_outputs.add(gated_outputs))\n",
        "        temporal_feature_outputs = temporal_feature_outputs.transpose(0, 1)\n",
        "\n",
        "        # Temporal Fusion Decoder\n",
        "\n",
        "        # Static enrcihment layer\n",
        "        static_enrichment_outputs = self.static_enrichment(temporal_feature_outputs, static_context_e)\n",
        "\n",
        "        # Temporal Self-attention layer\n",
        "        mask = self.get_mask(static_enrichment_outputs)\n",
        "        multihead_outputs, multihead_attention = self.multihead_attn(static_enrichment_outputs, static_enrichment_outputs, static_enrichment_outputs, mask=mask)\n",
        "\n",
        "        attention_gated_outputs = self.attention_gated_skip_connection(multihead_outputs)\n",
        "        attention_outputs = self.attention_add_norm(attention_gated_outputs.add(static_enrichment_outputs))\n",
        "\n",
        "        # Position-wise feed-forward layer\n",
        "        temporal_fusion_decoder_outputs = self.position_wise_feed_forward(attention_outputs)\n",
        "\n",
        "        # Output layer\n",
        "        gate_outputs = self.output_gated_skip_connection(temporal_fusion_decoder_outputs)\n",
        "        norm_outputs = self.output_add_norm(gate_outputs.add(temporal_feature_outputs))\n",
        "\n",
        "        output = self.output(norm_outputs[:, self.encoder_steps:, :]).view(-1,3)\n",
        "\n",
        "        attention_weights = {\n",
        "            'multihead_attention': multihead_attention,\n",
        "            'static_weights': static_weights[Ellipsis, 0],\n",
        "            'past_weights': past_weights[Ellipsis, 0, :],\n",
        "            'future_weights': future_weights[Ellipsis, 0, :]\n",
        "        }\n",
        "\n",
        "        return  output, attention_weights\n"
      ],
      "metadata": {
        "id": "BaeIv2OkxmPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFT_Dataset(Dataset):\n",
        "    def __init__(self, data, entity_column, time_column, target_column,\n",
        "                 input_columns, encoder_steps, decoder_steps):\n",
        "        self.encoder_steps = encoder_steps\n",
        "\n",
        "        inputs = []\n",
        "        outputs = []\n",
        "        entity = []\n",
        "        time = []\n",
        "\n",
        "        for e in data[entity_column].unique():\n",
        "            entity_group = data[data[entity_column] == e]\n",
        "            data_time_steps = len(entity_group)\n",
        "\n",
        "            # Minimum required length\n",
        "            min_required_length = max(encoder_steps, 30)\n",
        "            if data_time_steps >= min_required_length:\n",
        "                actual_decoder_steps = min(decoder_steps, data_time_steps)\n",
        "\n",
        "                # Process inputs\n",
        "                x = entity_group[input_columns].values.astype(np.float32)\n",
        "                inputs.append(np.stack([\n",
        "                    x[i:data_time_steps - (actual_decoder_steps - 1) + i, :]\n",
        "                    for i in range(actual_decoder_steps)\n",
        "                ], axis=1))\n",
        "\n",
        "                # Process outputs\n",
        "                y = entity_group[[target_column]].values.astype(np.float32)\n",
        "                outputs.append(np.stack([\n",
        "                    y[i:data_time_steps - (actual_decoder_steps - 1) + i, :]\n",
        "                    for i in range(actual_decoder_steps)\n",
        "                ], axis=1))\n",
        "\n",
        "                # Process entity\n",
        "                e_val = entity_group[[entity_column]].values.astype(np.float32)\n",
        "                entity.append(np.stack([\n",
        "                    e_val[i:data_time_steps - (actual_decoder_steps - 1) + i, :]\n",
        "                    for i in range(actual_decoder_steps)\n",
        "                ], axis=1))\n",
        "\n",
        "                # Process time\n",
        "                t = pd.to_datetime(entity_group[time_column]).astype(np.int64) // 10**9\n",
        "                time.append(np.stack([\n",
        "                    t[i:data_time_steps - (actual_decoder_steps - 1) + i]\n",
        "                    for i in range(actual_decoder_steps)\n",
        "                ], axis=1))\n",
        "\n",
        "        if not inputs:\n",
        "            raise ValueError(f\"No sequences long enough found in dataset. Minimum required length: {min_required_length}\")\n",
        "\n",
        "        # Concatenate all arrays\n",
        "        self.inputs = np.concatenate(inputs, axis=0)\n",
        "        self.outputs = np.concatenate(outputs, axis=0)\n",
        "        self.entity = np.concatenate(entity, axis=0)\n",
        "        self.time = np.concatenate(time, axis=0)\n",
        "\n",
        "        self.active_inputs = np.ones_like(self.outputs)\n",
        "\n",
        "        # Prepare sampled data dictionary\n",
        "        self.sampled_data = {\n",
        "            'inputs': self.inputs,\n",
        "            'outputs': self.outputs[:, self.encoder_steps:, :],\n",
        "            'active_entries': np.ones_like(self.outputs[:, self.encoder_steps:, :]),\n",
        "            'time': self.time,\n",
        "            'identifier': self.entity\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of samples in the dataset\n",
        "        return len(self.sampled_data['inputs'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Fetch a sample by index\n",
        "        return {\n",
        "            'inputs': torch.tensor(self.sampled_data['inputs'][idx], dtype=torch.float),\n",
        "            'outputs': torch.tensor(self.sampled_data['outputs'][idx], dtype=torch.float),\n",
        "            'active_entries': torch.tensor(self.sampled_data['active_entries'][idx], dtype=torch.float),\n",
        "            'time': torch.tensor(self.sampled_data['time'][idx], dtype=torch.long),\n",
        "            'identifier': torch.tensor(self.sampled_data['identifier'][idx], dtype=torch.float),\n",
        "        }"
      ],
      "metadata": {
        "id": "1FCJK9-txqZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_preprocessing(train, valid, test, real_columns, categorical_columns):\n",
        "    \"\"\"\n",
        "    Fit preprocessing scalers on combined training, validation, and test data\n",
        "    to ensure consistent handling of categories.\n",
        "    \"\"\"\n",
        "    # Use MinMaxScaler for real-valued columns\n",
        "    real_scalers = {\n",
        "        col: MinMaxScaler(feature_range=(0, 1)).fit(train[[col]])\n",
        "        for col in real_columns\n",
        "    }\n",
        "\n",
        "    # Combine all datasets to fit categorical scalers\n",
        "    combined = pd.concat([train, valid, test], axis=0)\n",
        "    categorical_scalers = {}\n",
        "    for col in categorical_columns:\n",
        "        if col == 'Symbol':\n",
        "            # Skip LabelEncoder for 'Symbol' (already numeric)\n",
        "            categorical_scalers[col] = None\n",
        "        else:\n",
        "            # Use LabelEncoder for other categorical columns\n",
        "            categorical_scalers[col] = LabelEncoder().fit(combined[col].apply(str).unique())\n",
        "\n",
        "    return real_scalers, categorical_scalers\n",
        "\n",
        "\n",
        "def transform_inputs(df, real_scalers, categorical_scalers, real_columns, categorical_columns):\n",
        "    \"\"\"\n",
        "    Transform data using fitted scalers, handling unseen categories gracefully.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "\n",
        "    # Transform each real-valued column\n",
        "    for col in real_columns:\n",
        "        out[col] = real_scalers[col].transform(df[[col]])\n",
        "\n",
        "    # Transform categorical columns with unseen category handling\n",
        "    for col in categorical_columns:\n",
        "        if col == 'Symbol':\n",
        "            # Skip transformation for 'Symbol' (already numeric)\n",
        "            continue\n",
        "        string_df = df[col].apply(str)\n",
        "        le = categorical_scalers[col]\n",
        "\n",
        "        # Replace unseen categories with 'unknown'\n",
        "        string_df = string_df.where(string_df.isin(le.classes_), 'unknown')\n",
        "\n",
        "        # Add 'unknown' to classes if it doesn't exist\n",
        "        if 'unknown' not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, 'unknown')\n",
        "\n",
        "        out[col] = le.transform(string_df)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "Lb_w8JIOxtnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9M011YNRxzNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=pd.read_csv('/content/Finalize.csv')\n",
        "raw_data.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "EVB6ouYLx0ak",
        "outputId": "875aec89-3dd3-4358-bece-96b6dbe652fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Date    LTP   High    Low   Qty   Turnover  SMA_5  SMA_20        RSI  \\\n",
              "0  5/13/2010  548.0  548.0  508.0  2519  1378182.0  504.8   488.8  54.090909   \n",
              "1  5/16/2010  525.0  555.0  510.0  3010  1590630.0  507.4   494.3  48.971193   \n",
              "2  5/17/2010  548.0  550.0  507.0  3039  1623947.0  520.2   502.1  59.663866   \n",
              "3  5/18/2010  571.0  571.0  540.0  2295  1271792.0  538.2   511.7  65.476190   \n",
              "\n",
              "       MACD  Volatility  Volume_MA5  Volume_MA20  month  day_of_week  \\\n",
              "0 -5.480371    0.044453    459137.6     338371.0      4            3   \n",
              "1 -3.143283    0.047071    742003.6     476387.5      4            6   \n",
              "2  0.558347    0.047851    960211.0     625151.8      4            0   \n",
              "3  5.286879    0.048448   1174888.2     742080.8      4            1   \n",
              "\n",
              "   day_of_month  week_of_year  days_from_start Symbol  \n",
              "0            12            18                0   NICA  \n",
              "1            15            18                3   NICA  \n",
              "2            16            19                4   NICA  \n",
              "3            17            19                5   NICA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c20ead11-eca6-41ac-94f3-7ec6162fb7d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>LTP</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Qty</th>\n",
              "      <th>Turnover</th>\n",
              "      <th>SMA_5</th>\n",
              "      <th>SMA_20</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Volatility</th>\n",
              "      <th>Volume_MA5</th>\n",
              "      <th>Volume_MA20</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>day_of_month</th>\n",
              "      <th>week_of_year</th>\n",
              "      <th>days_from_start</th>\n",
              "      <th>Symbol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/13/2010</td>\n",
              "      <td>548.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>508.0</td>\n",
              "      <td>2519</td>\n",
              "      <td>1378182.0</td>\n",
              "      <td>504.8</td>\n",
              "      <td>488.8</td>\n",
              "      <td>54.090909</td>\n",
              "      <td>-5.480371</td>\n",
              "      <td>0.044453</td>\n",
              "      <td>459137.6</td>\n",
              "      <td>338371.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>NICA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5/16/2010</td>\n",
              "      <td>525.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>3010</td>\n",
              "      <td>1590630.0</td>\n",
              "      <td>507.4</td>\n",
              "      <td>494.3</td>\n",
              "      <td>48.971193</td>\n",
              "      <td>-3.143283</td>\n",
              "      <td>0.047071</td>\n",
              "      <td>742003.6</td>\n",
              "      <td>476387.5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>NICA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5/17/2010</td>\n",
              "      <td>548.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>3039</td>\n",
              "      <td>1623947.0</td>\n",
              "      <td>520.2</td>\n",
              "      <td>502.1</td>\n",
              "      <td>59.663866</td>\n",
              "      <td>0.558347</td>\n",
              "      <td>0.047851</td>\n",
              "      <td>960211.0</td>\n",
              "      <td>625151.8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>NICA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5/18/2010</td>\n",
              "      <td>571.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>2295</td>\n",
              "      <td>1271792.0</td>\n",
              "      <td>538.2</td>\n",
              "      <td>511.7</td>\n",
              "      <td>65.476190</td>\n",
              "      <td>5.286879</td>\n",
              "      <td>0.048448</td>\n",
              "      <td>1174888.2</td>\n",
              "      <td>742080.8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>NICA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c20ead11-eca6-41ac-94f3-7ec6162fb7d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c20ead11-eca6-41ac-94f3-7ec6162fb7d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c20ead11-eca6-41ac-94f3-7ec6162fb7d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24c76f14-1c19-4856-8e2c-af1e96d99faa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24c76f14-1c19-4856-8e2c-af1e96d99faa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24c76f14-1c19-4856-8e2c-af1e96d99faa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_data"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('/content/Finalize.csv')\n",
        "numeric_columns = ['Qty', 'Turnover', 'LTP', 'High', 'Low']\n",
        "for col in numeric_columns:\n",
        "    raw_data[col] = pd.to_numeric(raw_data[col].astype(str).str.replace(',', ''), errors='coerce')\n",
        "raw_data[\"Date\"] = pd.to_datetime(raw_data[\"Date\"])"
      ],
      "metadata": {
        "id": "uYnXCaxZxz68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data['LTP_log'] = np.log1p(raw_data['LTP'])\n",
        "raw_data['LTP_pct_change'] = raw_data['LTP'].pct_change()"
      ],
      "metadata": {
        "id": "hSvuxFrvxzuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "xGaPix7Jx5y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data['Symbol'], symbol_labels = pd.factorize(raw_data['Symbol'])\n",
        "symbol_mapping = {idx: label for idx, label in enumerate(symbol_labels)}\n",
        "\n",
        "categorical_columns = ['Symbol','month', 'day_of_week', 'day_of_month', 'week_of_year']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    # Create ordered categorical with explicit categories\n",
        "    categories = range(int(raw_data[col].max()) + 1)  # Convert to int\n",
        "    raw_data[col] = pd.Categorical(raw_data[col],\n",
        "                                   categories=categories,\n",
        "                                   ordered=True)\n",
        "\n",
        "# Now you can check min and max\n",
        "for col in categorical_columns:\n",
        "    print(f\"Column: {col}\")\n",
        "    print(f\"Min: {raw_data[col].min()}, Max: {raw_data[col].max()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RauQ0DoXx_fL",
        "outputId": "666ad87f-43e5-48e2-e4dd-2e24bf0deb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: Symbol\n",
            "Min: 0, Max: 45\n",
            "\n",
            "Column: month\n",
            "Min: 0, Max: 12\n",
            "\n",
            "Column: day_of_week\n",
            "Min: 0, Max: 6\n",
            "\n",
            "Column: day_of_month\n",
            "Min: 0, Max: 31\n",
            "\n",
            "Column: week_of_year\n",
            "Min: 0, Max: 53\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = raw_data[raw_data['Date'] < '2021-01-01']\n",
        "valid = raw_data[(raw_data['Date'] >= '2021-01-01') & (raw_data['Date'] < '2023-01-01')]\n",
        "test = raw_data[raw_data['Date'] >= '2023-01-01']"
      ],
      "metadata": {
        "id": "7lAEWwxJyBv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_columns = [ \"LTP\", \"High\",\"Low\", # Targe         # Price-related\n",
        "    'SMA_5',        # Price-related moving average\n",
        "    'SMA_20',       # Price-related moving average\n",
        "    'RSI',          # Already 0-100 but better to normalize\n",
        "    'MACD',\n",
        "    'Volatility',\n",
        "    'days_from_start', 'LTP_log','LTP_pct_change'\n",
        "]\n",
        "\n",
        "categorical_columns = ['Symbol','month','day_of_week','day_of_month','week_of_year']\n",
        "\n",
        "volume_columns = ['Volume_MA5', 'Volume_MA20',\"Qty\",\"Turnover\"]\n",
        "raw_data[volume_columns] = np.log1p(raw_data[volume_columns])\n",
        "real_columns.extend(volume_columns)"
      ],
      "metadata": {
        "id": "OHVC_4isyCPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for infinity or -infinity in numeric columns only\n",
        "numeric_columns = train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Check for `inf` and `-inf` in the numeric columns\n",
        "inf_columns = numeric_columns[(train[numeric_columns] == float('inf')).any() | (train[numeric_columns] == float('-inf')).any()]\n",
        "print(\"Columns with infinity values:\", inf_columns)\n",
        "\n",
        "# Check for NaN in numeric columns\n",
        "nan_columns = numeric_columns[train[numeric_columns].isna().any()]\n",
        "print(\"Columns with NaN values:\", nan_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SSzzRslyEiK",
        "outputId": "06f61a80-a4c7-480e-c627-a8fcfa321cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with infinity values: Index([], dtype='object')\n",
            "Columns with NaN values: Index(['High', 'LTP_pct_change'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_scalers, categorical_scalers = fit_preprocessing(\n",
        "    train, valid, test, real_columns, categorical_columns\n",
        ")\n",
        "\n",
        "train = transform_inputs(train, real_scalers, categorical_scalers, real_columns, categorical_columns)\n",
        "valid = transform_inputs(valid, real_scalers, categorical_scalers, real_columns, categorical_columns)\n",
        "test = transform_inputs(test, real_scalers, categorical_scalers, real_columns, categorical_columns)"
      ],
      "metadata": {
        "id": "IxkQd-xsyGLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 100\n",
        "DROPOUT = 0.3\n",
        "LEARNING_RATE = 0.0001\n",
        "ENCODER_STEPS =128\n",
        "LOOKAHEAD = 40\n",
        "DECODER_STEPS = ENCODER_STEPS + LOOKAHEAD\n",
        "HIDDEN_LAYER_SIZE = 128\n",
        "EMBEDDING_DIMENSION = 16\n",
        "NUM_LSTM_LAYERS = 2\n",
        "NUM_ATTENTION_HEADS = 4\n",
        "QUANTILES = [0.1, 0.5, 0.9]\n",
        "\n",
        "\n",
        "# Dataset variables\n",
        "input_columns = [ \"LTP\",\"High\",\"Low\",'Symbol',\"Qty\",\"Turnover\",\"month\",\"day_of_week\", \"day_of_month\",\"week_of_year\",\"days_from_start\",\"SMA_5\", \"SMA_20\", \"RSI\", \"MACD\", \"Volatility\",\n",
        "    \"Volume_MA5\", \"Volume_MA20\"]\n",
        "target_column = \"LTP\"\n",
        "entity_column = \"Symbol\"\n",
        "time_column = \"Date\"\n",
        "col_to_idx = {col: idx for idx, col in enumerate(input_columns)}"
      ],
      "metadata": {
        "id": "c0XVRHE-yIDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"quantiles\": QUANTILES,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"dropout\": DROPOUT,\n",
        "    \"device\": DEVICE,\n",
        "    \"hidden_layer_size\": HIDDEN_LAYER_SIZE,\n",
        "    \"num_lstm_layers\": NUM_LSTM_LAYERS,\n",
        "    \"embedding_dim\": EMBEDDING_DIMENSION,\n",
        "    \"encoder_steps\": ENCODER_STEPS,\n",
        "    \"num_attention_heads\": NUM_ATTENTION_HEADS,\n",
        "    \"col_to_idx\": col_to_idx,\n",
        "    \"static_covariates\": [\"Symbol\"],\n",
        "    \"time_dependent_categorical\": [\"month\",\"day_of_week\",\"day_of_month\",\"week_of_year\"],\n",
        "    \"time_dependent_continuous\": [\"LTP\",\"High\",\"Low\",\"Qty\",\"Turnover\",\"days_from_start\",\"SMA_5\", \"SMA_20\", \"RSI\", \"MACD\", \"Volatility\",\"Volume_MA5\", \"Volume_MA20\"],\n",
        "    \"category_counts\": {\"Symbol\": 45,\"month\": 13, \"day_of_week\": 7, \"day_of_month\": 32, \"week_of_year\": 54},\n",
        "    \"known_time_dependent\": [\"month\",\"day_of_week\",\"day_of_month\",\"week_of_year\",\"days_from_start\"],\n",
        "    \"observed_time_dependent\": [\"LTP\",\"High\",\"Low\",\"Qty\",\"Turnover\",\"SMA_5\", \"SMA_20\", \"RSI\", \"MACD\", \"Volatility\",\"Volume_MA5\", \"Volume_MA20\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "Uc7_WATUyWT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = TFT_Dataset(train, entity_column, time_column, target_column, input_columns, ENCODER_STEPS, DECODER_STEPS)\n",
        "validation_data = TFT_Dataset(valid, entity_column, time_column, target_column, input_columns, ENCODER_STEPS, DECODER_STEPS)\n",
        "testing_data = TFT_Dataset(test, entity_column, time_column, target_column, input_columns, ENCODER_STEPS, DECODER_STEPS)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, num_workers=2, shuffle=False)\n",
        "valid_dataloader = DataLoader(validation_data, batch_size=BATCH_SIZE, num_workers=2, shuffle=False)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=BATCH_SIZE, num_workers=2, shuffle=False)"
      ],
      "metadata": {
        "id": "dSJngFldyeYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TemporalFusionTransformer(params)\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rar7WXBYz9iW",
        "outputId": "798cac58-6a66-4b54-ac07-070115fcb015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TemporalFusionTransformer(\n",
              "  (static_embeddings): ModuleDict(\n",
              "    (Symbol): Embedding(45, 16)\n",
              "  )\n",
              "  (static_variable_selection): VariableSelectionNetwork(\n",
              "    (flattened_inputs): GatedResidualNetwork(\n",
              "      (skip_layer): Linear(in_features=16, out_features=1, bias=True)\n",
              "      (dense1): Linear(in_features=16, out_features=128, bias=True)\n",
              "      (elu): ELU(alpha=1.0)\n",
              "      (dense2): Linear(in_features=128, out_features=1, bias=True)\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (gate): GLU(\n",
              "        (a): Linear(in_features=1, out_features=1, bias=True)\n",
              "        (sigmoid): Sigmoid()\n",
              "        (b): Linear(in_features=1, out_features=1, bias=True)\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (transformed_inputs): ModuleList(\n",
              "      (0): GatedResidualNetwork(\n",
              "        (skip_layer): Linear(in_features=16, out_features=128, bias=True)\n",
              "        (dense1): Linear(in_features=16, out_features=128, bias=True)\n",
              "        (elu): ELU(alpha=1.0)\n",
              "        (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (gate): GLU(\n",
              "          (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (softmax): Softmax(dim=-1)\n",
              "  )\n",
              "  (static_context_variable_selection): GatedResidualNetwork(\n",
              "    (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (static_context_enrichment): GatedResidualNetwork(\n",
              "    (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (static_context_state_h): GatedResidualNetwork(\n",
              "    (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (static_context_state_c): GatedResidualNetwork(\n",
              "    (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (temporal_cat_embeddings): ModuleDict(\n",
              "    (month): TemporalLayer(\n",
              "      (module): Embedding(13, 16)\n",
              "    )\n",
              "    (day_of_week): TemporalLayer(\n",
              "      (module): Embedding(7, 16)\n",
              "    )\n",
              "    (day_of_month): TemporalLayer(\n",
              "      (module): Embedding(32, 16)\n",
              "    )\n",
              "    (week_of_year): TemporalLayer(\n",
              "      (module): Embedding(54, 16)\n",
              "    )\n",
              "  )\n",
              "  (temporal_real_transformations): ModuleDict(\n",
              "    (LTP): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (High): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Low): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Qty): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Turnover): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (days_from_start): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (SMA_5): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (SMA_20): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (RSI): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (MACD): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Volatility): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Volume_MA5): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "    (Volume_MA20): TemporalLayer(\n",
              "      (module): Linear(in_features=1, out_features=16, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (past_variable_selection): VariableSelectionNetwork(\n",
              "    (flattened_inputs): GatedResidualNetwork(\n",
              "      (skip_layer): TemporalLayer(\n",
              "        (module): Linear(in_features=272, out_features=17, bias=True)\n",
              "      )\n",
              "      (c): TemporalLayer(\n",
              "        (module): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (dense1): TemporalLayer(\n",
              "        (module): Linear(in_features=272, out_features=128, bias=True)\n",
              "      )\n",
              "      (elu): ELU(alpha=1.0)\n",
              "      (dense2): TemporalLayer(\n",
              "        (module): Linear(in_features=128, out_features=17, bias=True)\n",
              "      )\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (gate): TemporalLayer(\n",
              "        (module): GLU(\n",
              "          (a): Linear(in_features=17, out_features=17, bias=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (b): Linear(in_features=17, out_features=17, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): TemporalLayer(\n",
              "        (module): LayerNorm((17,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (transformed_inputs): ModuleList(\n",
              "      (0-16): 17 x GatedResidualNetwork(\n",
              "        (skip_layer): TemporalLayer(\n",
              "          (module): Linear(in_features=16, out_features=128, bias=True)\n",
              "        )\n",
              "        (c): TemporalLayer(\n",
              "          (module): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (dense1): TemporalLayer(\n",
              "          (module): Linear(in_features=16, out_features=128, bias=True)\n",
              "        )\n",
              "        (elu): ELU(alpha=1.0)\n",
              "        (dense2): TemporalLayer(\n",
              "          (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (gate): TemporalLayer(\n",
              "          (module): GLU(\n",
              "            (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sigmoid): Sigmoid()\n",
              "            (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layer_norm): TemporalLayer(\n",
              "          (module): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (softmax): Softmax(dim=-1)\n",
              "  )\n",
              "  (future_variable_selection): VariableSelectionNetwork(\n",
              "    (flattened_inputs): GatedResidualNetwork(\n",
              "      (skip_layer): TemporalLayer(\n",
              "        (module): Linear(in_features=80, out_features=5, bias=True)\n",
              "      )\n",
              "      (c): TemporalLayer(\n",
              "        (module): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (dense1): TemporalLayer(\n",
              "        (module): Linear(in_features=80, out_features=128, bias=True)\n",
              "      )\n",
              "      (elu): ELU(alpha=1.0)\n",
              "      (dense2): TemporalLayer(\n",
              "        (module): Linear(in_features=128, out_features=5, bias=True)\n",
              "      )\n",
              "      (dropout): Dropout(p=0.3, inplace=False)\n",
              "      (gate): TemporalLayer(\n",
              "        (module): GLU(\n",
              "          (a): Linear(in_features=5, out_features=5, bias=True)\n",
              "          (sigmoid): Sigmoid()\n",
              "          (b): Linear(in_features=5, out_features=5, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): TemporalLayer(\n",
              "        (module): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (transformed_inputs): ModuleList(\n",
              "      (0-4): 5 x GatedResidualNetwork(\n",
              "        (skip_layer): TemporalLayer(\n",
              "          (module): Linear(in_features=16, out_features=128, bias=True)\n",
              "        )\n",
              "        (c): TemporalLayer(\n",
              "          (module): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (dense1): TemporalLayer(\n",
              "          (module): Linear(in_features=16, out_features=128, bias=True)\n",
              "        )\n",
              "        (elu): ELU(alpha=1.0)\n",
              "        (dense2): TemporalLayer(\n",
              "          (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.3, inplace=False)\n",
              "        (gate): TemporalLayer(\n",
              "          (module): GLU(\n",
              "            (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (sigmoid): Sigmoid()\n",
              "            (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (layer_norm): TemporalLayer(\n",
              "          (module): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (softmax): Softmax(dim=-1)\n",
              "  )\n",
              "  (lstm_encoder): LSTM(128, 128, num_layers=2, dropout=0.3)\n",
              "  (lstm_decoder): LSTM(128, 128, num_layers=2, dropout=0.3)\n",
              "  (gated_skip_connection): TemporalLayer(\n",
              "    (module): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (add_norm): TemporalLayer(\n",
              "    (module): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (static_enrichment): GatedResidualNetwork(\n",
              "    (c): TemporalLayer(\n",
              "      (module): Linear(in_features=128, out_features=128, bias=False)\n",
              "    )\n",
              "    (dense1): TemporalLayer(\n",
              "      (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): TemporalLayer(\n",
              "      (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): TemporalLayer(\n",
              "      (module): GLU(\n",
              "        (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (sigmoid): Sigmoid()\n",
              "        (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): TemporalLayer(\n",
              "      (module): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (multihead_attn): InterpretableMultiHeadAttention(\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "    (qs): ModuleList(\n",
              "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
              "    )\n",
              "    (ks): ModuleList(\n",
              "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
              "    )\n",
              "    (vs): ModuleList(\n",
              "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
              "    )\n",
              "    (attention): ScaledDotProductAttention(\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "      (softmax): Softmax(dim=2)\n",
              "    )\n",
              "    (linear): Linear(in_features=128, out_features=128, bias=False)\n",
              "  )\n",
              "  (attention_gated_skip_connection): TemporalLayer(\n",
              "    (module): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (attention_add_norm): TemporalLayer(\n",
              "    (module): BatchNorm1d(128, eps=128, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (position_wise_feed_forward): GatedResidualNetwork(\n",
              "    (dense1): TemporalLayer(\n",
              "      (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (elu): ELU(alpha=1.0)\n",
              "    (dense2): TemporalLayer(\n",
              "      (module): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "    (gate): TemporalLayer(\n",
              "      (module): GLU(\n",
              "        (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (sigmoid): Sigmoid()\n",
              "        (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm): TemporalLayer(\n",
              "      (module): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (output_gated_skip_connection): TemporalLayer(\n",
              "    (module): GLU(\n",
              "      (a): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (sigmoid): Sigmoid()\n",
              "      (b): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (output_add_norm): TemporalLayer(\n",
              "    (module): BatchNorm1d(128, eps=128, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (output): TemporalLayer(\n",
              "    (module): Linear(in_features=128, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import copy\n",
        "\n",
        "\n",
        "criterion = QuantileLoss(QUANTILES)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE,  weight_decay=1e-4)\n",
        "\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "# Early stopping variables\n",
        "patience = 30 # Number of epochs to wait for improvement\n",
        "best_val_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "\n",
        "print_every_k = 250\n",
        "losses = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    t0 = time.time()\n",
        "    print(f\"===== Epoch {epoch+1} =========\")\n",
        "    epoch_loss = 0.0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    # Add this debugging code before the model forward pass\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        labels = batch['outputs'][:,:,0].flatten().float().to(DEVICE)\n",
        "\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs, attention_weights = model(batch)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += loss.item()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if (i+1) % print_every_k == 0:\n",
        "            print(f\"Mini-batch {i+1} average loss: {round(running_loss / print_every_k, 5)}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    t1 = time.time()\n",
        "    avg_train_loss = epoch_loss / (i + 1)\n",
        "    print(f\"\\nEpoch trained in {round(time.time() - t0, 2)} seconds\")\n",
        "    print(\"Training Loss:\", round(epoch_loss / (i+1), 5), \"\\n\")\n",
        "    losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for batch in valid_dataloader:  # Use a validation DataLoader\n",
        "            labels = batch['outputs'][:,:,0].flatten().float().to(DEVICE)\n",
        "            outputs, _ = model(batch)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(valid_dataloader)\n",
        "    print(f\"Validation Loss: {round(avg_val_loss, 5)}\\n\")\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Early stopping logic\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(f\"Validation loss improved from {round(best_val_loss, 5)} to {round(avg_val_loss, 5)}. Saving model...\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_model_state = copy.deepcopy(model.state_dict())  # Save the best model state\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        print(f\"No improvement in validation loss for {early_stopping_counter} epochs.\")\n",
        "\n",
        "    if early_stopping_counter >= patience:\n",
        "        print(\"Early stopping triggered. Training stopped.\")\n",
        "        break\n",
        "\n",
        "# Load the best model state (if early stopping was triggered)\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"Loaded the best model state based on validation loss.\")\n",
        "\n",
        "    # Early stopping or learning rate scheduling can be added here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "smGkFdrVygRE",
        "outputId": "8c2ea7f1-a087-4c8c-f02a-7770dbc301ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Epoch 1 =========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batch 250 average loss: 0.11223\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 128 n 128 k 128 mat1_ld 128 mat2_ld 128 result_ld 128 abcType 0 computeType 68 scaleType 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b3c9e24e2f03>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-ae91b49e613c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Static variable selection and static covariate encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mstatic_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_context_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_context_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_context_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_context_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_static_covariate_encoders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Past input variable selection and LSTM encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-ae91b49e613c>\u001b[0m in \u001b[0;36mdefine_static_covariate_encoders\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Static context vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mstatic_context_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_context_variable_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_encoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Context for temporal variable selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mstatic_context_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_context_enrichment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_encoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Context for static enrichment layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mstatic_context_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_context_state_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_encoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Context for local processing of temporal features (encoder/decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mstatic_context_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_context_state_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_encoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Context for local processing of temporal features (encoder/decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-1a0c216c183c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, c)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0meta_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mgate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2f62de394be8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[1;32m     25\u001b[0m         \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 128 n 128 k 128 mat1_ld 128 mat2_ld 128 result_ld 128 abcType 0 computeType 68 scaleType 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "metadata": {
        "id": "KTdOBjy3yi5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump((real_scalers, categorical_scalers), \"scalers.pkl\")\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "DFm-XAZXyomp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses, label='Training Loss', color='blue', marker='o')\n",
        "plt.plot([i for i in range(len(losses))], [avg_val_loss] * len(losses), label='Validation Loss', color='red', linestyle='--')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5l8PPdeByqN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "def evaluate_model(model, test_dataloader, DEVICE):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test data.\n",
        "    Args:\n",
        "        model: Trained model.\n",
        "        test_dataloader: DataLoader for test data.\n",
        "        device: Device to perform computations (CPU/GPU).\n",
        "    Returns:\n",
        "        rmse, mae, mape: Evaluation metrics.\n",
        "        predictions, actuals: Arrays of predicted and actual values.\n",
        "    \"\"\"\n",
        "    model.eval()  # <-- Proper indentation starts here\n",
        "\n",
        "    # Store all quantiles\n",
        "    p10_list, p50_list, p90_list = [], [], []\n",
        "    actuals_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            # Get all quantile predictions\n",
        "            outputs, _ = model(batch)\n",
        "            p10_list.append(outputs[:, 0].cpu().numpy())\n",
        "            p50_list.append(outputs[:, 1].cpu().numpy())\n",
        "            p90_list.append(outputs[:, 2].cpu().numpy())\n",
        "\n",
        "            # Get actual values\n",
        "            actuals = batch['outputs'][:, :, 0].cpu().numpy().flatten()\n",
        "            actuals_list.append(actuals)\n",
        "\n",
        "    # Concatenate batches\n",
        "    p10 = np.concatenate(p10_list)\n",
        "    p50 = np.concatenate(p50_list)\n",
        "    p90 = np.concatenate(p90_list)\n",
        "    actuals = np.concatenate(actuals_list)\n",
        "\n",
        "    # Calculate MAE/RMSE for median\n",
        "    rmse = np.sqrt(mean_squared_error(actuals, p50))\n",
        "    mae = mean_absolute_error(actuals, p50)\n",
        "    mape = mean_absolute_percentage_error(actuals, p50) * 100\n",
        "\n",
        "    # Quantile loss calculation\n",
        "    def quantile_loss(q, y, f):\n",
        "        e = y - f\n",
        "        return np.mean(np.maximum(q * e, (q - 1) * e))\n",
        "\n",
        "    q_loss_10 = quantile_loss(0.1, actuals, p10)\n",
        "    q_loss_50 = quantile_loss(0.5, actuals, p50)\n",
        "    q_loss_90 = quantile_loss(0.9, actuals, p90)\n",
        "    total_q_loss = q_loss_10 + q_loss_50 + q_loss_90\n",
        "\n",
        "    print(\"\\nModel Performance Metrics:\")\n",
        "    print(f\"RMSE: {rmse:.2f}\")\n",
        "    print(f\"MAE: {mae:.2f}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")\n",
        "    print(f\"Quantile Loss (0.1): {q_loss_10:.2f}\")\n",
        "    print(f\"Quantile Loss (0.5): {q_loss_50:.2f}\")\n",
        "    print(f\"Quantile Loss (0.9): {q_loss_90:.2f}\")\n",
        "    print(f\"Total Quantile Loss: {total_q_loss:.2f}\")\n",
        "\n",
        "    # Return metrics and predictions\n",
        "    return rmse, mae, mape, p50, actuals, (q_loss_10, q_loss_50, q_loss_90)  # Corrected return statement\n",
        "\n",
        "\n",
        "def plot_predictions(predictions, actuals, title=\"Actual vs Predicted Values\"):\n",
        "    \"\"\"\n",
        "    Plot actual vs predicted values for visualization.\n",
        "    Args:\n",
        "        predictions: Array of predicted values.\n",
        "        actuals: Array of actual values.\n",
        "        title: Title of the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Main prediction plot\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(actuals, label='Actual', color='blue', alpha=0.7)\n",
        "    plt.plot(predictions, label='Predicted', color='red', alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Stock Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Error plot\n",
        "    plt.subplot(2, 1, 2)\n",
        "    error = predictions - actuals\n",
        "    plt.plot(error, color='green', alpha=0.7)\n",
        "    plt.title('Prediction Error Over Time')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Error (Predicted - Actual)')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Additional error distribution plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(error, bins=50, color='green', alpha=0.7)\n",
        "    plt.title('Error Distribution')\n",
        "    plt.xlabel('Prediction Error')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the model and create plots\n",
        "rmse, mae, mape, predictions, actuals, quantile_losses = evaluate_model(model, test_dataloader, DEVICE)\n",
        "plot_predictions(predictions, actuals, \"Stock Price Prediction Results\")"
      ],
      "metadata": {
        "id": "OZ0zrcYLyt20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "nPAOcbX5yxNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = torch.load('checkpoint.pth')"
      ],
      "metadata": {
        "id": "qs1p4QDzyyYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_future_prices(model, test_dataloader, real_scalers, categorical_scalers, real_columns, categorical_columns, num_prediction_days=40, symbol_mapping=None):\n",
        "    model.eval()\n",
        "    future_predictions = []\n",
        "    real_scalers, categorical_scalers = joblib.load(\"scalers.pkl\")\n",
        "\n",
        "    # Get the last batch from test_dataloader for each symbol\n",
        "    last_known_data = {}\n",
        "    test_end_date = pd.Timestamp('2025-01-10')  # Set the actual test end date\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            batch_size = batch['inputs'].size(0)\n",
        "\n",
        "            # Get the actual timestamps for the last known data point\n",
        "            timestamps = batch['time'][:, -1].cpu().numpy()  # Get last timestamp for each sequence\n",
        "            identifiers = batch['identifier'][:, -1, :].cpu().numpy()\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                symbol = int(identifiers[i][0])\n",
        "                current_timestamp = timestamps[i]\n",
        "\n",
        "                # Update only if this is the most recent data for this symbol\n",
        "                if symbol not in last_known_data or current_timestamp > last_known_data[symbol]['last_timestamp']:\n",
        "                    last_known_data[symbol] = {\n",
        "                        'inputs': batch['inputs'][i:i+1],\n",
        "                        'time': batch['time'][i:i+1],\n",
        "                        'identifier': batch['identifier'][i:i+1],\n",
        "                        'last_timestamp': current_timestamp\n",
        "                    }\n",
        "\n",
        "    # Generate predictions for each symbol\n",
        "    for symbol, last_data in last_known_data.items():\n",
        "        try:\n",
        "            # Start predictions from day after test end date\n",
        "            print(f\"\\nGenerating predictions for symbol {symbol} starting from {test_end_date}\")\n",
        "\n",
        "            # Generate future dates (trading days only) starting from test_end_date\n",
        "            future_dates = pd.date_range(\n",
        "                start=test_end_date + pd.Timedelta(days=1),\n",
        "                periods=num_prediction_days,\n",
        "                freq='B'  # Business days only\n",
        "            )\n",
        "\n",
        "            # Make prediction using the last known data\n",
        "            prediction_batch = {\n",
        "                'inputs': last_data['inputs'].to(DEVICE),\n",
        "                'time': last_data['time'].to(DEVICE),\n",
        "                'identifier': last_data['identifier'].to(DEVICE)\n",
        "            }\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs, _ = model(prediction_batch)\n",
        "            predictions = outputs.detach().cpu().numpy()\n",
        "\n",
        "            # Ensure we're using the correct scaler for LTP\n",
        "            if isinstance(real_scalers['LTP'], str) and real_scalers['LTP'].endswith('.joblib'):\n",
        "                ltp_scaler = load(real_scalers['LTP'])\n",
        "            else:\n",
        "                ltp_scaler = real_scalers['LTP']\n",
        "\n",
        "            # Unscale predictions\n",
        "            scaled_predictions = predictions[:, 1].reshape(-1, 1)\n",
        "            unscaled_predictions = ltp_scaler.inverse_transform(scaled_predictions)\n",
        "\n",
        "            # Get confidence intervals\n",
        "            lower_bound = ltp_scaler.inverse_transform(predictions[:, 0].reshape(-1, 1))\n",
        "            upper_bound = ltp_scaler.inverse_transform(predictions[:, 2].reshape(-1, 1))\n",
        "\n",
        "            # Decode symbol back to original name using symbol_mapping\n",
        "            if symbol_mapping is not None:\n",
        "                original_symbol = symbol_mapping.get(symbol, f\"Unknown_Symbol_{symbol}\")\n",
        "            else:\n",
        "                original_symbol = symbol  # Fallback to numeric symbol if no mapping is provided\n",
        "\n",
        "            print(f\"Processing predictions for symbol: {original_symbol}\")\n",
        "\n",
        "            # Store predictions with dates\n",
        "            for idx, date in enumerate(future_dates):\n",
        "                future_predictions.append({\n",
        "                    'Date': date,\n",
        "                    'Symbol': original_symbol,\n",
        "                    'Predicted_LTP': float(unscaled_predictions[idx][0]),\n",
        "                    'Lower_Bound': float(lower_bound[idx][0]),\n",
        "                    'Upper_Bound': float(upper_bound[idx][0])\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing symbol {symbol}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Create DataFrame and save to CSV\n",
        "    predictions_df = pd.DataFrame(future_predictions)\n",
        "    predictions_df = predictions_df.sort_values(['Symbol', 'Date'])\n",
        "\n",
        "    # Save predictions to CSV\n",
        "    filename = f'future_predictions_{datetime.now().strftime(\"%Y%m%d22213\")}.csv'\n",
        "    predictions_df.to_csv(filename, index=False)\n",
        "    print(f\"\\nFuture predictions saved to {filename}\")\n",
        "\n",
        "    return predictions_df\n",
        "\n",
        "future_predictions = predict_future_prices(\n",
        "    model=model,\n",
        "    test_dataloader=test_dataloader,\n",
        "    real_scalers=real_scalers,\n",
        "    categorical_scalers=categorical_scalers,\n",
        "    real_columns=real_columns,\n",
        "    categorical_columns=categorical_columns,\n",
        "    num_prediction_days=40,\n",
        "    symbol_mapping=symbol_mapping  # Pass the symbol mapping here\n",
        ")"
      ],
      "metadata": {
        "id": "c89WANL4y0zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/kaggle/working/future_predictions_2025012822213.csv\")"
      ],
      "metadata": {
        "id": "65WooXvwy3HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgZhY3ec0a52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}